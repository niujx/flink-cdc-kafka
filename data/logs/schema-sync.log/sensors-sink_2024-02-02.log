17:00:50.067 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 6.2.0.Final
17:00:50.261 [main] INFO  com.rock.cdc.kafka.schema.sync.App - Starting App using Java 1.8.0_281 on bogon with PID 89561 (/Users/yanshi/work/github/flink-cdc-kafka/flink-cdc-pipeline-connector-kafka-schema-sync/target/classes started by yanshi in /Users/yanshi/work/github/flink-cdc-kafka)
17:00:50.285 [main] INFO  com.rock.cdc.kafka.schema.sync.App - The following profiles are active: production
17:00:51.582 [main] WARN  org.springframework.boot.context.config.ConfigDataEnvironment - Property 'spring.profiles' imported from location 'class path resource [application.yaml]' is invalid and should be replaced with 'spring.config.activate.on-profile' [origin: class path resource [application.yaml] - 45:13]
17:00:51.583 [main] WARN  org.springframework.boot.context.config.ConfigDataEnvironment - Property 'spring.profiles' imported from location 'class path resource [application.yaml]' is invalid and should be replaced with 'spring.config.activate.on-profile' [origin: class path resource [application.yaml] - 10:13]
17:00:55.142 [main] INFO  org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor - No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
17:00:55.163 [main] INFO  org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor - No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
17:00:55.458 [main] INFO  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.stream.config.BindersHealthIndicatorAutoConfiguration' of type [org.springframework.cloud.stream.config.BindersHealthIndicatorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
17:00:55.466 [main] INFO  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'bindersHealthContributor' of type [org.springframework.cloud.stream.config.BindersHealthIndicatorAutoConfiguration$BindersHealthContributor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
17:00:55.468 [main] INFO  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'bindersHealthIndicatorListener' of type [org.springframework.cloud.stream.config.BindersHealthIndicatorAutoConfiguration$BindersHealthIndicatorListener] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
17:00:55.485 [main] INFO  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
17:00:55.505 [main] INFO  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
17:00:55.507 [main] INFO  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
17:00:57.289 [main] INFO  org.springframework.boot.web.embedded.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9999 (http)
17:00:57.322 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9999"]
17:00:57.323 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
17:00:57.324 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/9.0.52]
17:00:57.704 [main] INFO  org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
17:00:57.705 [main] INFO  org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 6119 ms
17:00:59.804 [main] INFO  org.springframework.cloud.stream.messaging.DirectWithAttributesChannel - Channel 'application.sinkProcess-in-0' has 1 subscriber(s).
17:01:00.824 [main] INFO  org.springframework.boot.actuate.endpoint.web.EndpointLinksResolver - Exposing 1 endpoint(s) beneath base path '/actuator'
17:01:00.991 [main] INFO  org.springframework.integration.endpoint.EventDrivenConsumer - Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
17:01:00.991 [main] INFO  org.springframework.integration.channel.PublishSubscribeChannel - Channel 'application.errorChannel' has 1 subscriber(s).
17:01:00.992 [main] INFO  org.springframework.integration.endpoint.EventDrivenConsumer - started bean '_org.springframework.integration.errorLogger'
17:01:00.993 [main] INFO  org.springframework.integration.endpoint.EventDrivenConsumer - Adding {service-activator:app.error.serviceActivator} as a subscriber to the 'sensors-event-log.sensors-group-20210825.errors' channel
17:01:00.993 [main] INFO  org.springframework.integration.channel.DirectChannel - Channel 'application.sensors-event-log.sensors-group-20210825.errors' has 1 subscriber(s).
17:01:00.993 [main] INFO  org.springframework.integration.endpoint.EventDrivenConsumer - started bean 'app.error.serviceActivator'
17:01:00.996 [main] INFO  org.springframework.cloud.stream.binder.DefaultBinderFactory - Creating binder: kafka
17:01:01.817 [main] INFO  org.springframework.cloud.stream.binder.DefaultBinderFactory - Caching the binder: kafka
17:01:01.817 [main] INFO  org.springframework.cloud.stream.binder.DefaultBinderFactory - Retrieving cached binder: kafka
17:01:02.029 [main] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [10.195.40.142:9092, 10.195.40.117:9092, 10.195.40.119:9092, 10.195.40.68:9092, 10.195.40.80:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

17:01:02.520 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
17:01:02.521 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
17:01:02.521 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1706864462513
17:01:02.524 [main] INFO  org.springframework.cloud.stream.binder.kafka.provisioning.KafkaTopicProvisioner - Auto creation of topics is disabled.
17:01:02.567 [kafka-admin-client-thread | adminclient-1] INFO  org.apache.kafka.common.utils.AppInfoParser - App info kafka.admin.client for adminclient-1 unregistered
17:01:02.568 [kafka-admin-client-thread | adminclient-1] INFO  org.apache.kafka.clients.admin.internals.AdminMetadataManager - [AdminClient clientId=adminclient-1] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: Call(callName=fetchMetadata, deadlineMs=1706864492524, tries=1, nextAllowedTryMs=-9223372036854775709) timed out at 9223372036854775807 after 1 attempt(s)
Caused by: org.apache.kafka.common.errors.TimeoutException: Timed out waiting to send the call. Call: fetchMetadata
17:01:02.585 [kafka-admin-client-thread | adminclient-1] INFO  org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
17:01:02.586 [kafka-admin-client-thread | adminclient-1] INFO  org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
17:01:02.586 [kafka-admin-client-thread | adminclient-1] INFO  org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
17:01:02.605 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.195.40.142:9092, 10.195.40.117:9092, 10.195.40.119:9092, 10.195.40.68:9092, 10.195.40.80:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-yanshiaaaaa-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = yanshiaaaaa
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

17:01:02.703 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
17:01:02.703 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
17:01:02.704 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1706864462703
17:01:03.769 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-yanshiaaaaa-1, groupId=yanshiaaaaa] Cluster ID: gI_tQQPqQQ-sWskEhiiviQ
17:01:03.782 [main] INFO  org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
17:01:03.784 [main] INFO  org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
17:01:03.785 [main] INFO  org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
17:01:03.790 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-yanshiaaaaa-1 unregistered
17:01:03.845 [main] INFO  org.springframework.cloud.stream.binder.BinderErrorChannel - Channel 'catalog-meta-data.yanshiaaaaa.errors' has 1 subscriber(s).
17:01:03.846 [main] INFO  org.springframework.cloud.stream.binder.BinderErrorChannel - Channel 'catalog-meta-data.yanshiaaaaa.errors' has 0 subscriber(s).
17:01:03.846 [main] INFO  org.springframework.cloud.stream.binder.BinderErrorChannel - Channel 'catalog-meta-data.yanshiaaaaa.errors' has 1 subscriber(s).
17:01:03.846 [main] INFO  org.springframework.cloud.stream.binder.BinderErrorChannel - Channel 'catalog-meta-data.yanshiaaaaa.errors' has 2 subscriber(s).
17:01:03.882 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.195.40.142:9092, 10.195.40.117:9092, 10.195.40.119:9092, 10.195.40.68:9092, 10.195.40.80:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-yanshiaaaaa-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = yanshiaaaaa
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

17:01:03.895 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
17:01:03.895 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
17:01:03.895 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1706864463895
17:01:03.910 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Subscribed to topic(s): catalog-meta-data
17:01:03.923 [main] INFO  org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter - started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@334d825c
17:01:03.930 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9999"]
17:01:03.968 [main] INFO  org.springframework.boot.web.embedded.tomcat.TomcatWebServer - Tomcat started on port(s): 9999 (http) with context path ''
17:01:04.002 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Cluster ID: gI_tQQPqQQ-sWskEhiiviQ
17:01:04.006 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Discovered group coordinator 10.195.40.80:9092 (id: 2147483642 rack: null)
17:01:04.010 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] (Re-)joining group
17:01:04.092 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] (Re-)joining group
17:01:04.095 [main] INFO  com.rock.cdc.kafka.schema.sync.App - Started App in 15.525 seconds (JVM running for 21.595)
17:01:07.130 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Successfully joined group with generation Generation{generationId=1, memberId='consumer-yanshiaaaaa-2-2431455a-b91f-45fb-a619-e8c663ff896c', protocol='range'}
17:01:07.134 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Finished assignment for group at generation 1: {consumer-yanshiaaaaa-2-2431455a-b91f-45fb-a619-e8c663ff896c=Assignment(partitions=[catalog-meta-data-0, catalog-meta-data-1, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-6])}
17:01:07.162 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Successfully synced group in generation Generation{generationId=1, memberId='consumer-yanshiaaaaa-2-2431455a-b91f-45fb-a619-e8c663ff896c', protocol='range'}
17:01:07.163 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Notifying assignor about the new Assignment(partitions=[catalog-meta-data-0, catalog-meta-data-1, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-6])
17:01:07.167 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Adding newly assigned partitions: catalog-meta-data-6, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-0, catalog-meta-data-1
17:01:07.196 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Found no committed offset for partition catalog-meta-data-6
17:01:07.196 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Found no committed offset for partition catalog-meta-data-4
17:01:07.196 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Found no committed offset for partition catalog-meta-data-5
17:01:07.196 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Found no committed offset for partition catalog-meta-data-2
17:01:07.196 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Found no committed offset for partition catalog-meta-data-3
17:01:07.196 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Found no committed offset for partition catalog-meta-data-0
17:01:07.197 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Found no committed offset for partition catalog-meta-data-1
17:01:07.298 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Resetting offset for partition catalog-meta-data-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.119:9092 (id: 3 rack: null)], epoch=absent}}.
17:01:07.300 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Resetting offset for partition catalog-meta-data-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.119:9092 (id: 3 rack: null)], epoch=absent}}.
17:01:07.302 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Resetting offset for partition catalog-meta-data-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.80:9092 (id: 5 rack: null)], epoch=absent}}.
17:01:07.302 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Resetting offset for partition catalog-meta-data-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.68:9092 (id: 4 rack: null)], epoch=absent}}.
17:01:07.303 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Resetting offset for partition catalog-meta-data-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.117:9092 (id: 2 rack: null)], epoch=absent}}.
17:01:07.303 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Resetting offset for partition catalog-meta-data-0 to position FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.117:9092 (id: 2 rack: null)], epoch=absent}}.
17:01:07.304 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Resetting offset for partition catalog-meta-data-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.142:9092 (id: 1 rack: null)], epoch=absent}}.
17:01:07.305 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.springframework.cloud.stream.binder.kafka.KafkaMessageChannelBinder$2 - yanshiaaaaa: partitions assigned: [catalog-meta-data-6, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-0, catalog-meta-data-1]
17:01:20.444 [kafka-coordinator-heartbeat-thread | yanshiaaaaa] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Group coordinator 10.195.40.80:9092 (id: 2147483642 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
17:01:20.552 [kafka-coordinator-heartbeat-thread | yanshiaaaaa] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Discovered group coordinator 10.195.40.80:9092 (id: 2147483642 rack: null)
17:01:21.074 [kafka-coordinator-heartbeat-thread | yanshiaaaaa] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-yanshiaaaaa-2-2431455a-b91f-45fb-a619-e8c663ff896c', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
17:02:48.510 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] ERROR org.springframework.integration.handler.LoggingHandler - org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.cloud.stream.function.FunctionConfiguration$FunctionToDestinationBinder$1@645c59a7]; nested exception is java.lang.NullPointerException, failedMessage=GenericMessage [payload=byte[3680], headers={skip-input-type-conversion=false, kafka_offset=8, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@41751f49, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedMessageKey=[B@7c916000, kafka_receivedTopic=catalog-meta-data, kafka_receivedTimestamp=1706861090328, contentType=application/json, kafka_groupId=yanshiaaaaa}]
	at org.springframework.integration.support.utils.IntegrationUtils.wrapInHandlingExceptionIfNecessary(IntegrationUtils.java:192)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:65)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:208)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:398)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:79)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:457)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:431)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:123)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:117)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:41)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2323)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2304)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2218)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2143)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2025)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1707)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at com.rock.cdc.kafka.schema.sync.App.handAlterTable(App.java:139)
	at com.rock.cdc.kafka.schema.sync.App.lambda$sinkProcess$0(App.java:89)
	at org.springframework.cloud.function.context.catalog.SimpleFunctionRegistry$FunctionInvocationWrapper.invokeConsumer(SimpleFunctionRegistry.java:854)
	at org.springframework.cloud.function.context.catalog.SimpleFunctionRegistry$FunctionInvocationWrapper.doApply(SimpleFunctionRegistry.java:643)
	at org.springframework.cloud.function.context.catalog.SimpleFunctionRegistry$FunctionInvocationWrapper.apply(SimpleFunctionRegistry.java:489)
	at org.springframework.cloud.stream.function.PartitionAwareFunctionWrapper.apply(PartitionAwareFunctionWrapper.java:77)
	at org.springframework.cloud.stream.function.FunctionConfiguration$FunctionWrapper.apply(FunctionConfiguration.java:727)
	at org.springframework.cloud.stream.function.FunctionConfiguration$FunctionToDestinationBinder$1.handleMessageInternal(FunctionConfiguration.java:560)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	... 32 more

17:02:48.537 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Seeking to offset 8 for partition catalog-meta-data-0
17:02:48.540 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] ERROR org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.cloud.stream.function.FunctionConfiguration$FunctionToDestinationBinder$1@645c59a7]; nested exception is java.lang.NullPointerException, failedMessage=GenericMessage [payload=byte[3680], headers={skip-input-type-conversion=false, kafka_offset=8, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@41751f49, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedMessageKey=[B@7c916000, kafka_receivedTopic=catalog-meta-data, kafka_receivedTimestamp=1706861090328, contentType=application/json, kafka_groupId=yanshiaaaaa}]
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2360) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2229) [spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2143) [spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2025) [spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1707) [spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274) [spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266) [spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161) [spring-kafka-2.7.6.jar:2.7.6]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_281]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_281]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_281]
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.cloud.stream.function.FunctionConfiguration$FunctionToDestinationBinder$1@645c59a7]; nested exception is java.lang.NullPointerException, failedMessage=GenericMessage [payload=byte[3680], headers={skip-input-type-conversion=false, kafka_offset=8, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@41751f49, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedMessageKey=[B@7c916000, kafka_receivedTopic=catalog-meta-data, kafka_receivedTimestamp=1706861090328, contentType=application/json, kafka_groupId=yanshiaaaaa}]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2376) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2343) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2304) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2218) ~[spring-kafka-2.7.6.jar:2.7.6]
	... 9 more
Caused by: org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.cloud.stream.function.FunctionConfiguration$FunctionToDestinationBinder$1@645c59a7]; nested exception is java.lang.NullPointerException
	at org.springframework.integration.support.utils.IntegrationUtils.wrapInHandlingExceptionIfNecessary(IntegrationUtils.java:192) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:65) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187) ~[spring-messaging-5.3.9.jar:5.3.9]
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166) ~[spring-messaging-5.3.9.jar:5.3.9]
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47) ~[spring-messaging-5.3.9.jar:5.3.9]
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109) ~[spring-messaging-5.3.9.jar:5.3.9]
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:208) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:398) ~[spring-integration-kafka-5.5.3.jar:5.5.3]
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:79) ~[spring-integration-kafka-5.5.3.jar:5.5.3]
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:457) ~[spring-integration-kafka-5.5.3.jar:5.5.3]
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:431) ~[spring-integration-kafka-5.5.3.jar:5.5.3]
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:123) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329) ~[spring-retry-1.3.1.jar:?]
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255) ~[spring-retry-1.3.1.jar:?]
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:117) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:41) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2323) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2304) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2218) ~[spring-kafka-2.7.6.jar:2.7.6]
	... 9 more
Caused by: java.lang.NullPointerException
	at com.rock.cdc.kafka.schema.sync.App.handAlterTable(App.java:139) ~[classes/:?]
	at com.rock.cdc.kafka.schema.sync.App.lambda$sinkProcess$0(App.java:89) ~[classes/:?]
	at org.springframework.cloud.function.context.catalog.SimpleFunctionRegistry$FunctionInvocationWrapper.invokeConsumer(SimpleFunctionRegistry.java:854) ~[spring-cloud-function-context-3.1.3.jar:3.1.3]
	at org.springframework.cloud.function.context.catalog.SimpleFunctionRegistry$FunctionInvocationWrapper.doApply(SimpleFunctionRegistry.java:643) ~[spring-cloud-function-context-3.1.3.jar:3.1.3]
	at org.springframework.cloud.function.context.catalog.SimpleFunctionRegistry$FunctionInvocationWrapper.apply(SimpleFunctionRegistry.java:489) ~[spring-cloud-function-context-3.1.3.jar:3.1.3]
	at org.springframework.cloud.stream.function.PartitionAwareFunctionWrapper.apply(PartitionAwareFunctionWrapper.java:77) ~[spring-cloud-stream-3.1.3.jar:3.1.3]
	at org.springframework.cloud.stream.function.FunctionConfiguration$FunctionWrapper.apply(FunctionConfiguration.java:727) ~[spring-cloud-stream-3.1.3.jar:3.1.3]
	at org.springframework.cloud.stream.function.FunctionConfiguration$FunctionToDestinationBinder$1.handleMessageInternal(FunctionConfiguration.java:560) ~[spring-cloud-stream-3.1.3.jar:3.1.3]
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187) ~[spring-messaging-5.3.9.jar:5.3.9]
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166) ~[spring-messaging-5.3.9.jar:5.3.9]
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47) ~[spring-messaging-5.3.9.jar:5.3.9]
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109) ~[spring-messaging-5.3.9.jar:5.3.9]
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:208) ~[spring-integration-core-5.5.3.jar:5.5.3]
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:398) ~[spring-integration-kafka-5.5.3.jar:5.5.3]
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:79) ~[spring-integration-kafka-5.5.3.jar:5.5.3]
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:457) ~[spring-integration-kafka-5.5.3.jar:5.5.3]
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:431) ~[spring-integration-kafka-5.5.3.jar:5.5.3]
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:123) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329) ~[spring-retry-1.3.1.jar:?]
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255) ~[spring-retry-1.3.1.jar:?]
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:117) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:41) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2323) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2304) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2218) ~[spring-kafka-2.7.6.jar:2.7.6]
	... 9 more
17:02:48.550 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
17:02:48.550 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Lost previously assigned partitions catalog-meta-data-6, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-0, catalog-meta-data-1
17:02:48.551 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.springframework.cloud.stream.binder.kafka.KafkaMessageChannelBinder$2 - yanshiaaaaa: partitions lost: [catalog-meta-data-6, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-0, catalog-meta-data-1]
17:02:48.552 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.springframework.cloud.stream.binder.kafka.KafkaMessageChannelBinder$2 - yanshiaaaaa: partitions revoked: [catalog-meta-data-6, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-0, catalog-meta-data-1]
17:02:48.554 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] (Re-)joining group
17:02:48.564 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] (Re-)joining group
17:02:51.588 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Successfully joined group with generation Generation{generationId=3, memberId='consumer-yanshiaaaaa-2-35276c1d-9e79-45ee-9a7f-b0969b5310d7', protocol='range'}
17:02:51.588 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Finished assignment for group at generation 3: {consumer-yanshiaaaaa-2-35276c1d-9e79-45ee-9a7f-b0969b5310d7=Assignment(partitions=[catalog-meta-data-0, catalog-meta-data-1, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-6])}
17:02:51.627 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Successfully synced group in generation Generation{generationId=3, memberId='consumer-yanshiaaaaa-2-35276c1d-9e79-45ee-9a7f-b0969b5310d7', protocol='range'}
17:02:51.627 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Notifying assignor about the new Assignment(partitions=[catalog-meta-data-0, catalog-meta-data-1, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-6])
17:02:51.627 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Adding newly assigned partitions: catalog-meta-data-6, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-0, catalog-meta-data-1
17:02:51.654 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Found no committed offset for partition catalog-meta-data-6
17:02:51.654 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Found no committed offset for partition catalog-meta-data-4
17:02:51.654 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Found no committed offset for partition catalog-meta-data-5
17:02:51.655 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Found no committed offset for partition catalog-meta-data-2
17:02:51.655 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Found no committed offset for partition catalog-meta-data-3
17:02:51.655 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Found no committed offset for partition catalog-meta-data-0
17:02:51.655 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Found no committed offset for partition catalog-meta-data-1
17:02:51.677 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Resetting offset for partition catalog-meta-data-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.119:9092 (id: 3 rack: null)], epoch=absent}}.
17:02:51.678 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Resetting offset for partition catalog-meta-data-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.119:9092 (id: 3 rack: null)], epoch=absent}}.
17:02:51.679 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Resetting offset for partition catalog-meta-data-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.80:9092 (id: 5 rack: null)], epoch=absent}}.
17:02:51.684 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Resetting offset for partition catalog-meta-data-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.68:9092 (id: 4 rack: null)], epoch=absent}}.
17:02:51.685 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Resetting offset for partition catalog-meta-data-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.117:9092 (id: 2 rack: null)], epoch=absent}}.
17:02:51.685 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Resetting offset for partition catalog-meta-data-0 to position FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.117:9092 (id: 2 rack: null)], epoch=absent}}.
17:02:51.685 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-yanshiaaaaa-2, groupId=yanshiaaaaa] Resetting offset for partition catalog-meta-data-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.142:9092 (id: 1 rack: null)], epoch=absent}}.
17:02:51.686 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.springframework.cloud.stream.binder.kafka.KafkaMessageChannelBinder$2 - yanshiaaaaa: partitions assigned: [catalog-meta-data-6, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-0, catalog-meta-data-1]
