16:54:10.116 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 6.2.0.Final
16:54:10.245 [main] INFO  com.rock.cdc.kafka.schema.sync.App - Starting App using Java 1.8.0_281 on bogon with PID 36748 (/Users/yanshi/work/github/flink-cdc-kafka/flink-cdc-pipeline-connector-kafka-schema-sync/target/classes started by yanshi in /Users/yanshi/work/github/flink-cdc-kafka)
16:54:10.254 [main] INFO  com.rock.cdc.kafka.schema.sync.App - The following profiles are active: production
16:54:10.989 [main] WARN  org.springframework.boot.context.config.ConfigDataEnvironment - Property 'spring.profiles' imported from location 'class path resource [application.yaml]' is invalid and should be replaced with 'spring.config.activate.on-profile' [origin: class path resource [application.yaml] - 45:13]
16:54:10.989 [main] WARN  org.springframework.boot.context.config.ConfigDataEnvironment - Property 'spring.profiles' imported from location 'class path resource [application.yaml]' is invalid and should be replaced with 'spring.config.activate.on-profile' [origin: class path resource [application.yaml] - 10:13]
16:54:13.347 [main] INFO  org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor - No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
16:54:13.368 [main] INFO  org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor - No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
16:54:13.617 [main] INFO  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.stream.config.BindersHealthIndicatorAutoConfiguration' of type [org.springframework.cloud.stream.config.BindersHealthIndicatorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
16:54:13.624 [main] INFO  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'bindersHealthContributor' of type [org.springframework.cloud.stream.config.BindersHealthIndicatorAutoConfiguration$BindersHealthContributor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
16:54:13.627 [main] INFO  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'bindersHealthIndicatorListener' of type [org.springframework.cloud.stream.config.BindersHealthIndicatorAutoConfiguration$BindersHealthIndicatorListener] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
16:54:13.648 [main] INFO  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
16:54:13.670 [main] INFO  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
16:54:13.673 [main] INFO  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
16:54:14.318 [main] INFO  org.springframework.boot.web.embedded.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9999 (http)
16:54:14.344 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9999"]
16:54:14.345 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
16:54:14.346 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/9.0.52]
16:54:14.659 [main] INFO  org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
16:54:14.660 [main] INFO  org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 3669 ms
16:54:19.869 [main] INFO  org.springframework.cloud.stream.messaging.DirectWithAttributesChannel - Channel 'application.sinkProcess-in-0' has 1 subscriber(s).
16:54:20.804 [main] INFO  org.springframework.boot.actuate.endpoint.web.EndpointLinksResolver - Exposing 1 endpoint(s) beneath base path '/actuator'
16:54:20.952 [main] INFO  org.springframework.integration.endpoint.EventDrivenConsumer - Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
16:54:20.952 [main] INFO  org.springframework.integration.channel.PublishSubscribeChannel - Channel 'application.errorChannel' has 1 subscriber(s).
16:54:20.953 [main] INFO  org.springframework.integration.endpoint.EventDrivenConsumer - started bean '_org.springframework.integration.errorLogger'
16:54:20.953 [main] INFO  org.springframework.integration.endpoint.EventDrivenConsumer - Adding {service-activator:app.error.serviceActivator} as a subscriber to the 'schema-sync.errors' channel
16:54:20.953 [main] INFO  org.springframework.integration.channel.DirectChannel - Channel 'application.schema-sync.errors' has 1 subscriber(s).
16:54:20.953 [main] INFO  org.springframework.integration.endpoint.EventDrivenConsumer - started bean 'app.error.serviceActivator'
16:54:20.955 [main] INFO  org.springframework.cloud.stream.binder.DefaultBinderFactory - Creating binder: kafka
16:54:21.385 [main] INFO  org.springframework.cloud.stream.binder.DefaultBinderFactory - Caching the binder: kafka
16:54:21.386 [main] INFO  org.springframework.cloud.stream.binder.DefaultBinderFactory - Retrieving cached binder: kafka
16:54:21.539 [main] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [10.195.40.142:9092, 10.195.40.117:9092, 10.195.40.119:9092, 10.195.40.68:9092, 10.195.40.80:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

16:54:21.685 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
16:54:21.685 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
16:54:21.685 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1707209661679
16:54:21.689 [main] INFO  org.springframework.cloud.stream.binder.kafka.provisioning.KafkaTopicProvisioner - Auto creation of topics is disabled.
16:54:22.293 [kafka-admin-client-thread | adminclient-1] INFO  org.apache.kafka.common.utils.AppInfoParser - App info kafka.admin.client for adminclient-1 unregistered
16:54:22.294 [kafka-admin-client-thread | adminclient-1] INFO  org.apache.kafka.clients.admin.internals.AdminMetadataManager - [AdminClient clientId=adminclient-1] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: Call(callName=fetchMetadata, deadlineMs=1707209691689, tries=1, nextAllowedTryMs=-9223372036854775709) timed out at 9223372036854775807 after 1 attempt(s)
Caused by: org.apache.kafka.common.errors.TimeoutException: Timed out waiting to send the call. Call: fetchMetadata
16:54:22.314 [kafka-admin-client-thread | adminclient-1] INFO  org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
16:54:22.314 [kafka-admin-client-thread | adminclient-1] INFO  org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
16:54:22.314 [kafka-admin-client-thread | adminclient-1] INFO  org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
16:54:22.337 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [10.195.40.142:9092, 10.195.40.117:9092, 10.195.40.119:9092, 10.195.40.68:9092, 10.195.40.80:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-20240205111-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 20240205111
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

16:54:22.429 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
16:54:22.430 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
16:54:22.430 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1707209662429
16:54:22.699 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-20240205111-1, groupId=20240205111] Cluster ID: gI_tQQPqQQ-sWskEhiiviQ
16:54:22.711 [main] INFO  org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
16:54:22.712 [main] INFO  org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
16:54:22.712 [main] INFO  org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
16:54:22.716 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-20240205111-1 unregistered
16:54:22.766 [main] INFO  org.springframework.cloud.stream.binder.BinderErrorChannel - Channel 'catalog-meta-data.20240205111.errors' has 1 subscriber(s).
16:54:22.766 [main] INFO  org.springframework.cloud.stream.binder.BinderErrorChannel - Channel 'catalog-meta-data.20240205111.errors' has 0 subscriber(s).
16:54:22.766 [main] INFO  org.springframework.cloud.stream.binder.BinderErrorChannel - Channel 'catalog-meta-data.20240205111.errors' has 1 subscriber(s).
16:54:22.767 [main] INFO  org.springframework.cloud.stream.binder.BinderErrorChannel - Channel 'catalog-meta-data.20240205111.errors' has 2 subscriber(s).
16:54:22.801 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [10.195.40.142:9092, 10.195.40.117:9092, 10.195.40.119:9092, 10.195.40.68:9092, 10.195.40.80:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-20240205111-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 20240205111
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

16:54:22.811 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
16:54:22.811 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
16:54:22.812 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1707209662811
16:54:22.823 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Subscribed to topic(s): catalog-meta-data
16:54:22.838 [main] INFO  org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter - started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@47541b42
16:54:22.847 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9999"]
16:54:22.875 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Cluster ID: gI_tQQPqQQ-sWskEhiiviQ
16:54:22.877 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Discovered group coordinator 10.195.40.142:9092 (id: 2147483646 rack: null)
16:54:22.880 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] (Re-)joining group
16:54:22.882 [main] INFO  org.springframework.boot.web.embedded.tomcat.TomcatWebServer - Tomcat started on port(s): 9999 (http) with context path ''
16:54:22.911 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] (Re-)joining group
16:54:22.941 [main] INFO  com.rock.cdc.kafka.schema.sync.App - Started App in 13.759 seconds (JVM running for 19.077)
16:54:25.916 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Successfully joined group with generation Generation{generationId=1, memberId='consumer-20240205111-2-ab6e840c-bbfa-4f6a-a17b-ef161a8d216b', protocol='range'}
16:54:25.920 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Finished assignment for group at generation 1: {consumer-20240205111-2-ab6e840c-bbfa-4f6a-a17b-ef161a8d216b=Assignment(partitions=[catalog-meta-data-0, catalog-meta-data-1, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-6])}
16:54:25.933 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Successfully synced group in generation Generation{generationId=1, memberId='consumer-20240205111-2-ab6e840c-bbfa-4f6a-a17b-ef161a8d216b', protocol='range'}
16:54:25.934 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Notifying assignor about the new Assignment(partitions=[catalog-meta-data-0, catalog-meta-data-1, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-6])
16:54:25.937 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Adding newly assigned partitions: catalog-meta-data-6, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-0, catalog-meta-data-1
16:54:25.945 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Found no committed offset for partition catalog-meta-data-6
16:54:25.945 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Found no committed offset for partition catalog-meta-data-4
16:54:25.945 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Found no committed offset for partition catalog-meta-data-5
16:54:25.945 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Found no committed offset for partition catalog-meta-data-2
16:54:25.945 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Found no committed offset for partition catalog-meta-data-3
16:54:25.945 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Found no committed offset for partition catalog-meta-data-0
16:54:25.946 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Found no committed offset for partition catalog-meta-data-1
16:54:25.955 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Found no committed offset for partition catalog-meta-data-6
16:54:25.956 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Found no committed offset for partition catalog-meta-data-4
16:54:25.956 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Found no committed offset for partition catalog-meta-data-5
16:54:25.956 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Found no committed offset for partition catalog-meta-data-2
16:54:25.956 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Found no committed offset for partition catalog-meta-data-3
16:54:25.956 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Found no committed offset for partition catalog-meta-data-0
16:54:25.957 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Found no committed offset for partition catalog-meta-data-1
16:54:25.995 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Resetting offset for partition catalog-meta-data-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.68:9092 (id: 4 rack: null)], epoch=absent}}.
16:54:25.997 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Resetting offset for partition catalog-meta-data-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.142:9092 (id: 1 rack: null)], epoch=absent}}.
16:54:25.997 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Resetting offset for partition catalog-meta-data-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.119:9092 (id: 3 rack: null)], epoch=absent}}.
16:54:25.997 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Resetting offset for partition catalog-meta-data-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.119:9092 (id: 3 rack: null)], epoch=absent}}.
16:54:25.998 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Resetting offset for partition catalog-meta-data-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.80:9092 (id: 5 rack: null)], epoch=absent}}.
16:54:25.998 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Resetting offset for partition catalog-meta-data-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.117:9092 (id: 2 rack: null)], epoch=absent}}.
16:54:25.998 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Resetting offset for partition catalog-meta-data-0 to position FetchPosition{offset=37, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.117:9092 (id: 2 rack: null)], epoch=absent}}.
16:54:26.011 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.springframework.cloud.stream.binder.kafka.KafkaMessageChannelBinder$2 - 20240205111: partitions assigned: [catalog-meta-data-6, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-0, catalog-meta-data-1]
16:55:34.714 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  com.rock.cdc.kafka.schema.sync.App - receive schema change App.SyncObjectIdentifier(catalogName=ods_test, databaseName=ods_test, objectName=ods_cdc_db_gmcf_emc_t_emc_bill_info)
16:55:35.356 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.hadoop.hive.conf.HiveConf - Found configuration file null
16:55:36.127 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.flink.table.catalog.hive.HiveCatalog - Setting hive conf dir as /Users/yanshi/Downloads
16:55:36.199 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16:55:36.549 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.flink.table.catalog.hive.HiveCatalog - Created HiveCatalog 'ods_test'
16:55:36.963 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.hadoop.hive.metastore.HiveMetaStoreClient - Trying to connect to metastore with URI thrift://10.159.41.69:9083
16:55:37.032 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.hadoop.hive.metastore.HiveMetaStoreClient - Opened a connection to metastore, current connections: 1
16:55:37.117 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.hadoop.hive.metastore.HiveMetaStoreClient - Connected to metastore.
16:55:37.117 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.hadoop.hive.metastore.RetryingMetaStoreClient - RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.metastore.HiveMetaStoreClient ugi=root (auth:SIMPLE) retries=1 delay=1 lifetime=0
16:55:37.492 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.flink.table.catalog.hive.HiveCatalog - Connected to Hive metastore
16:56:19.511 [kafka-coordinator-heartbeat-thread | 20240205111] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Group coordinator 10.195.40.142:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
16:56:19.512 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  com.rock.cdc.kafka.schema.sync.App - receive schema change App.SyncObjectIdentifier(catalogName=ods_test, databaseName=ods_test, objectName=ods_cdc_db_gmcf_emc_t_emc_bill_info)
16:56:23.277 [kafka-coordinator-heartbeat-thread | 20240205111] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Discovered group coordinator 10.195.40.142:9092 (id: 2147483646 rack: null)
16:56:23.393 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-20240205111-2-ab6e840c-bbfa-4f6a-a17b-ef161a8d216b', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
16:56:23.399 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] ERROR org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Offset commit failed on partition catalog-meta-data-0 at offset 39: The coordinator is not aware of this member.
16:56:23.400 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] OffsetCommit failed with Generation{generationId=1, memberId='consumer-20240205111-2-ab6e840c-bbfa-4f6a-a17b-ef161a8d216b', protocol='range'}: The coordinator is not aware of this member.
16:56:23.401 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] ERROR org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer exception
java.lang.IllegalStateException: This error handler cannot process 'org.apache.kafka.clients.consumer.CommitFailedException's; no record information is available
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:200) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.handleConsumerException(KafkaMessageListenerContainer.java:1602) [spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1210) [spring-kafka-2.7.6.jar:2.7.6]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_281]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_281]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_281]
Caused by: org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:1256) ~[kafka-clients-2.7.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:1163) ~[kafka-clients-2.7.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:1173) ~[kafka-clients-2.7.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:1148) ~[kafka-clients-2.7.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:206) ~[kafka-clients-2.7.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:169) ~[kafka-clients-2.7.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:129) ~[kafka-clients-2.7.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:602) ~[kafka-clients-2.7.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:412) ~[kafka-clients-2.7.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:297) ~[kafka-clients-2.7.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236) ~[kafka-clients-2.7.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215) ~[kafka-clients-2.7.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1005) ~[kafka-clients-2.7.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1495) ~[kafka-clients-2.7.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_281]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_281]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_281]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_281]
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344) ~[spring-aop-5.3.9.jar:5.3.9]
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:208) ~[spring-aop-5.3.9.jar:5.3.9]
	at com.sun.proxy.$Proxy128.commitSync(Unknown Source) ~[?:?]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doCommitSync(KafkaMessageListenerContainer.java:2710) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.commitSync(KafkaMessageListenerContainer.java:2705) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.commitIfNecessary(KafkaMessageListenerContainer.java:2691) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.processCommits(KafkaMessageListenerContainer.java:2489) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1235) ~[spring-kafka-2.7.6.jar:2.7.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161) ~[spring-kafka-2.7.6.jar:2.7.6]
	... 3 more
16:56:23.406 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
16:56:23.406 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Lost previously assigned partitions catalog-meta-data-6, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-0, catalog-meta-data-1
16:56:23.407 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.springframework.cloud.stream.binder.kafka.KafkaMessageChannelBinder$2 - 20240205111: partitions lost: [catalog-meta-data-6, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-0, catalog-meta-data-1]
16:56:23.407 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.springframework.cloud.stream.binder.kafka.KafkaMessageChannelBinder$2 - 20240205111: partitions revoked: [catalog-meta-data-6, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-0, catalog-meta-data-1]
16:56:23.408 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] (Re-)joining group
16:56:23.418 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] (Re-)joining group
16:56:26.429 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Successfully joined group with generation Generation{generationId=3, memberId='consumer-20240205111-2-86942e43-4e0e-464a-9b6d-065f51aa5d28', protocol='range'}
16:56:26.431 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Finished assignment for group at generation 3: {consumer-20240205111-2-86942e43-4e0e-464a-9b6d-065f51aa5d28=Assignment(partitions=[catalog-meta-data-0, catalog-meta-data-1, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-6])}
16:56:26.453 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Successfully synced group in generation Generation{generationId=3, memberId='consumer-20240205111-2-86942e43-4e0e-464a-9b6d-065f51aa5d28', protocol='range'}
16:56:26.453 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Notifying assignor about the new Assignment(partitions=[catalog-meta-data-0, catalog-meta-data-1, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-6])
16:56:26.454 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Adding newly assigned partitions: catalog-meta-data-6, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-0, catalog-meta-data-1
16:56:26.486 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Setting offset for partition catalog-meta-data-6 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.119:9092 (id: 3 rack: null)], epoch=absent}}
16:56:26.487 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Setting offset for partition catalog-meta-data-4 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.142:9092 (id: 1 rack: null)], epoch=absent}}
16:56:26.487 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Setting offset for partition catalog-meta-data-5 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.117:9092 (id: 2 rack: null)], epoch=absent}}
16:56:26.487 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Setting offset for partition catalog-meta-data-2 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.68:9092 (id: 4 rack: null)], epoch=absent}}
16:56:26.488 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Setting offset for partition catalog-meta-data-3 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.80:9092 (id: 5 rack: null)], epoch=absent}}
16:56:26.488 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Setting offset for partition catalog-meta-data-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.117:9092 (id: 2 rack: null)], epoch=absent}}
16:56:26.488 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Setting offset for partition catalog-meta-data-1 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.195.40.119:9092 (id: 3 rack: null)], epoch=absent}}
16:56:26.489 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.springframework.cloud.stream.binder.kafka.KafkaMessageChannelBinder$2 - 20240205111: partitions assigned: [catalog-meta-data-6, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-0, catalog-meta-data-1]
16:56:26.537 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  com.rock.cdc.kafka.schema.sync.App - receive schema change App.SyncObjectIdentifier(catalogName=ods_test, databaseName=ods_test, objectName=ods_cdc_db_gmcf_emc_t_emc_bill_info)
16:56:38.339 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  com.rock.cdc.kafka.schema.sync.App - receive schema change App.SyncObjectIdentifier(catalogName=ods_test, databaseName=ods_test, objectName=ods_cdc_db_gmcf_emc_t_emc_bill_info)
16:56:38.475 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  com.rock.cdc.kafka.schema.sync.App - receive schema change App.SyncObjectIdentifier(catalogName=ods_test, databaseName=ods_test, objectName=ods_cdc_db_gmcf_emc_t_emc_bill_info)
16:58:18.407 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  com.rock.cdc.kafka.schema.sync.App - receive schema change App.SyncObjectIdentifier(catalogName=ods_test, databaseName=ods_test, objectName=ods_cdc_db_gmcf_emc_t_emc_bill_info)
16:58:58.030 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  com.rock.cdc.kafka.schema.sync.App - receive schema change App.SyncObjectIdentifier(catalogName=ods_test, databaseName=ods_test, objectName=ods_cdc_db_gmcf_emc_t_emc_bill_info)
17:01:02.213 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Revoke previously assigned partitions catalog-meta-data-6, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-0, catalog-meta-data-1
17:01:02.213 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.springframework.cloud.stream.binder.kafka.KafkaMessageChannelBinder$2 - 20240205111: partitions revoked: [catalog-meta-data-6, catalog-meta-data-4, catalog-meta-data-5, catalog-meta-data-2, catalog-meta-data-3, catalog-meta-data-0, catalog-meta-data-1]
17:01:02.213 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Member consumer-20240205111-2-86942e43-4e0e-464a-9b6d-065f51aa5d28 sending LeaveGroup request to coordinator 10.195.40.142:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
17:01:02.214 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-20240205111-2, groupId=20240205111] Unsubscribed all topics or patterns and assigned partitions
17:01:02.508 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
17:01:02.509 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
17:01:02.510 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
17:01:02.518 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.apache.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-20240205111-2 unregistered
17:01:02.519 [KafkaConsumerDestination{consumerDestinationName='catalog-meta-data', partitions=0, dlqName='null'}.container-0-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - 20240205111: Consumer stopped
17:01:02.523 [SpringApplicationShutdownHook] INFO  org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter - stopped org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@47541b42
17:01:02.553 [SpringApplicationShutdownHook] INFO  org.springframework.cloud.stream.binder.BinderErrorChannel - Channel 'application.catalog-meta-data.20240205111.errors' has 1 subscriber(s).
17:01:02.555 [SpringApplicationShutdownHook] INFO  org.springframework.cloud.stream.binder.BinderErrorChannel - Channel 'application.catalog-meta-data.20240205111.errors' has 0 subscriber(s).
17:01:02.558 [SpringApplicationShutdownHook] INFO  org.springframework.integration.endpoint.EventDrivenConsumer - Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
17:01:02.558 [SpringApplicationShutdownHook] INFO  org.springframework.integration.channel.PublishSubscribeChannel - Channel 'application.errorChannel' has 0 subscriber(s).
17:01:02.559 [SpringApplicationShutdownHook] INFO  org.springframework.integration.endpoint.EventDrivenConsumer - stopped bean '_org.springframework.integration.errorLogger'
17:01:02.559 [SpringApplicationShutdownHook] INFO  org.springframework.integration.endpoint.EventDrivenConsumer - Removing {service-activator:app.error.serviceActivator} as a subscriber to the 'schema-sync.errors' channel
17:01:02.560 [SpringApplicationShutdownHook] INFO  org.springframework.integration.channel.DirectChannel - Channel 'application.schema-sync.errors' has 0 subscriber(s).
17:01:02.560 [SpringApplicationShutdownHook] INFO  org.springframework.integration.endpoint.EventDrivenConsumer - stopped bean 'app.error.serviceActivator'
17:01:02.586 [SpringApplicationShutdownHook] INFO  org.apache.hadoop.hive.metastore.HiveMetaStoreClient - Closed a connection to metastore, current connections: 0
17:01:02.586 [SpringApplicationShutdownHook] INFO  org.apache.flink.table.catalog.hive.HiveCatalog - Close connection to Hive metastore
